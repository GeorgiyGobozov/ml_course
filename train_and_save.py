# train_and_save.py - –æ–±—É—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, 
    f1_score, confusion_matrix, classification_report
)
import time
import json
import joblib
import pickle
import argparse
import sys
import warnings
import os
from datetime import datetime
from pathlib import Path

warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ sklearn
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

class ModelTrainer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    """
    
    def __init__(self, dataset_path):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞ –º–æ–¥–µ–ª–µ–π
        
        Args:
            dataset_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É dataset.npz
        """
        self.dataset_path = Path(dataset_path)
        self.dataset_name = ""
        self.classes = []
        self.input_shape = None
        self.grayscale = True
        self.results = {}
        self.models_dir = Path("trained_models")
        self.models_dir.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
        self.model_types_dir = self.models_dir / "model_types"
        self.model_types_dir.mkdir(exist_ok=True)
        
        self.best_model_dir = self.models_dir / "best_model"
        self.best_model_dir.mkdir(exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self._load_dataset()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self._prepare_data()
    
    def _load_dataset(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {self.dataset_path}")
        
        try:
            data = np.load(self.dataset_path)
            
            self.X_train = data['X_train']
            self.y_train = data['y_train']
            self.X_val = data['X_val']
            self.y_val = data['y_val']
            self.X_test = data['X_test']
            self.y_test = data['y_test']
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata_path = self.dataset_path.parent / 'metadata' / 'dataset_metadata.json'
            if metadata_path.exists():
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                self.dataset_name = metadata.get('dataset_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç')
                self.classes = metadata.get('classes', [])
                self.input_shape = metadata.get('input_shape', self.X_train[0].shape)
                self.grayscale = metadata.get('grayscale', True)
                
                print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–¢–ê–°–ï–¢–ï:")
                print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {self.dataset_name}")
                print(f"  –ö–ª–∞—Å—Å—ã ({len(self.classes)}): {', '.join(self.classes)}")
                print(f"  –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {self.X_train.shape[0]} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                print(f"  –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {self.X_test.shape[0]} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                print(f"  –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {self.input_shape}")
                
            else:
                print("‚ö†Ô∏è  –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                self.classes = [f'Class_{i}' for i in range(len(np.unique(self.y_train)))]
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
            sys.exit(1)
    
    def _prepare_data(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        print("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
        n_train = self.X_train.shape[0]
        n_val = self.X_val.shape[0]
        n_test = self.X_test.shape[0]
        
        self.X_train_flat = self.X_train.reshape(n_train, -1)
        self.X_val_flat = self.X_val.reshape(n_val, -1)
        self.X_test_flat = self.X_test.reshape(n_test, -1)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏
        self.X_train_full = np.vstack([self.X_train_flat, self.X_val_flat])
        self.y_train_full = np.concatenate([self.y_train, self.y_val])
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        print(f"  –í—Å–µ–≥–æ –æ–±—É—á–∞—é—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {self.X_train_full.shape[0]}")
        print(f"  –¢–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {self.X_test_flat.shape[0]}")
        print(f"  –†–∞–∑–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {self.X_train_full.shape[1]}")
    
    def train_model(self, model, model_name, save_model=True):
        """
        –û–±—É—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        """
        print(f"\nüéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
        
        start_time = time.time()
        model.fit(self.X_train_full, self.y_train_full)
        train_time = time.time() - start_time
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        start_time = time.time()
        y_pred = model.predict(self.X_test_flat)
        predict_time = time.time() - start_time
        
        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='weighted', zero_division=0)
        
        results = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'train_time': train_time,
            'predict_time': predict_time,
            'predictions': y_pred,
            'model_name': model_name,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.4f}")
        print(f"  F1-–º–µ—Ä–∞: {f1:.4f}")
        print(f"  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {train_time:.2f} —Å–µ–∫")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        if save_model:
            self._save_model(model, model_name, results)
        
        self.results[model_name] = results
        return results
    
    def _save_model(self, model, model_name, results):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ñ–∞–π–ª"""
        # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        safe_name = model_name.replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_")
        filename = f"{safe_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é joblib
        model_path = self.model_types_dir / f"{filename}.joblib"
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –º–æ–¥–µ–ª—å—é –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        model_data = {
            'model': model,
            'model_name': model_name,
            'dataset_name': self.dataset_name,
            'classes': self.classes,
            'input_shape': self.input_shape,
            'grayscale': self.grayscale,
            'accuracy': results['accuracy'],
            'f1_score': results['f1_score'],
            'train_time': results['train_time'],
            'timestamp': results['timestamp']
        }
        
        joblib.dump(model_data, model_path)
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ pickle –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        pickle_path = self.model_types_dir / f"{filename}.pkl"
        with open(pickle_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"  üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        return model_path
    
    def train_all_models(self):
        """–û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        print("\n" + "="*70)
        print("üöÄ –û–ë–£–ß–ï–ù–ò–ï –ò –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
        print("="*70)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        models = [
            ("Logistic_Regression", LogisticRegression(max_iter=1000, random_state=42)),
            ("SVM_Linear", SVC(kernel='linear', random_state=42, probability=True)),
            ("SVM_RBF", SVC(kernel='rbf', random_state=42, probability=True)),
            ("Random_Forest", RandomForestClassifier(n_estimators=100, random_state=42)),
            ("KNN", KNeighborsClassifier(n_neighbors=5)),
            ("Decision_Tree", DecisionTreeClassifier(random_state=42)),
            ("Naive_Bayes", GaussianNB()),
            ("MLP", MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42))
        ]
        
        for name, model in models:
            try:
                self.train_model(model, name, save_model=True)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ {name}: {e}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        self._select_best_model()
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        self._create_summary_report()
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._visualize_results()
        
        print(f"\n‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {self.models_dir}")
    
    def _select_best_model(self):
        """–í—ã–±–æ—Ä –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏"""
        if not self.results:
            print("‚ö†Ô∏è  –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏")
            return
        
        # –ù–∞—Ö–æ–¥–∏–º –º–æ–¥–µ–ª—å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
        best_model_name = max(self.results.keys(), key=lambda x: self.results[x]['accuracy'])
        best_result = self.results[best_model_name]
        
        print(f"\nüèÜ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {best_model_name}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å: {best_result['accuracy']:.4f}")
        print(f"  F1-–º–µ—Ä–∞: {best_result['f1_score']:.4f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É
        best_model_data = {
            'model': best_result['model'],
            'model_name': best_model_name,
            'dataset_name': self.dataset_name,
            'classes': self.classes,
            'input_shape': self.input_shape,
            'grayscale': self.grayscale,
            'accuracy': best_result['accuracy'],
            'f1_score': best_result['f1_score'],
            'train_time': best_result['train_time'],
            'timestamp': best_result['timestamp'],
            'all_results': self.results
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # 1. Joblib
        joblib_path = self.best_model_dir / f"best_model_{timestamp}.joblib"
        joblib.dump(best_model_data, joblib_path)
        
        # 2. Pickle
        pickle_path = self.best_model_dir / f"best_model_{timestamp}.pkl"
        with open(pickle_path, 'wb') as f:
            pickle.dump(best_model_data, f)
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ "latest" –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        latest_path = self.best_model_dir / "best_model_latest.joblib"
        joblib.dump(best_model_data, latest_path)
        
        print(f"üíæ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞:")
        print(f"  –û—Å–Ω–æ–≤–Ω–∞—è: {joblib_path}")
        print(f"  –ü–æ—Å–ª–µ–¥–Ω—è—è: {latest_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        info_path = self.best_model_dir / "best_model_info.txt"
        with open(info_path, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò\n")
            f.write("="*60 + "\n\n")
            f.write(f"–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {best_model_name}\n")
            f.write(f"–î–∞—Ç–∞—Å–µ—Ç: {self.dataset_name}\n")
            f.write(f"–î–∞—Ç–∞ –æ–±—É—á–µ–Ω–∏—è: {best_result['timestamp']}\n")
            f.write(f"–¢–æ—á–Ω–æ—Å—Ç—å: {best_result['accuracy']:.4f}\n")
            f.write(f"F1-–º–µ—Ä–∞: {best_result['f1_score']:.4f}\n")
            f.write(f"–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {best_result['train_time']:.2f} —Å–µ–∫\n")
            f.write(f"–ö–ª–∞—Å—Å—ã: {', '.join(self.classes)}\n")
            f.write(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {self.input_shape}\n")
        
        self.best_model_info = best_model_data
    
    def _create_summary_report(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        if not self.results:
            return
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –≤ JSON
        report_data = {
            'dataset_name': self.dataset_name,
            'classes': self.classes,
            'training_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'models': {}
        }
        
        for model_name, res in self.results.items():
            report_data['models'][model_name] = {
                'accuracy': float(res['accuracy']),
                'f1_score': float(res['f1_score']),
                'precision': float(res['precision']),
                'recall': float(res['recall']),
                'train_time': float(res['train_time']),
                'predict_time': float(res['predict_time'])
            }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        if self.results:
            best_model = max(self.results.keys(), key=lambda x: self.results[x]['accuracy'])
            report_data['best_model'] = {
                'name': best_model,
                'accuracy': float(self.results[best_model]['accuracy']),
                'f1_score': float(self.results[best_model]['f1_score'])
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_path = self.models_dir / "training_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìä –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        import pandas as pd
        
        csv_data = []
        for model_name, res in self.results.items():
            csv_data.append({
                'Model': model_name,
                'Accuracy': res['accuracy'],
                'F1_Score': res['f1_score'],
                'Precision': res['precision'],
                'Recall': res['recall'],
                'Train_Time_s': res['train_time'],
                'Predict_Time_s': res['predict_time']
            })
        
        df = pd.DataFrame(csv_data)
        df.to_csv(self.models_dir / "models_comparison.csv", index=False)
        print(f"üìã –¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {self.models_dir / 'models_comparison.csv'}")
    
    def _visualize_results(self):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        if len(self.results) < 2:
            return
        
        plt.figure(figsize=(14, 8))
        
        # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
        plt.subplot(2, 3, 1)
        model_names = list(self.results.keys())
        accuracies = [self.results[name]['accuracy'] for name in model_names]
        
        colors = plt.cm.Set3(np.arange(len(model_names)) / len(model_names))
        bars = plt.bar(model_names, accuracies, color=colors)
        plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π', fontsize=14)
        plt.ylabel('Accuracy')
        plt.ylim(0, 1.1)
        plt.xticks(rotation=45)
        
        for bar, acc in zip(bars, accuracies):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{acc:.3f}', ha='center', va='bottom', fontsize=10)
        
        # 2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ F1-–º–µ—Ä—ã
        plt.subplot(2, 3, 2)
        f1_scores = [self.results[name]['f1_score'] for name in model_names]
        
        bars = plt.bar(model_names, f1_scores, color=colors)
        plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ F1-–º–µ—Ä—ã', fontsize=14)
        plt.ylabel('F1-Score')
        plt.ylim(0, 1.1)
        plt.xticks(rotation=45)
        
        for bar, f1 in zip(bars, f1_scores):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{f1:.3f}', ha='center', va='bottom', fontsize=10)
        
        # 3. –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
        plt.subplot(2, 3, 3)
        train_times = [self.results[name]['train_time'] for name in model_names]
        
        plt.bar(model_names, train_times, color='lightcoral')
        plt.title('–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π', fontsize=14)
        plt.ylabel('–í—Ä–µ–º—è (—Å–µ–∫)')
        plt.xticks(rotation=45)
        
        # 4. –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        plt.subplot(2, 3, 4)
        best_model_name = max(self.results.keys(), key=lambda x: self.results[x]['accuracy'])
        best_predictions = self.results[best_model_name]['predictions']
        
        cm = confusion_matrix(self.y_test, best_predictions)
        
        if self.classes and len(self.classes) == cm.shape[0]:
            tick_labels = self.classes
        else:
            tick_labels = [f'Class {i}' for i in range(cm.shape[0])]
        
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=tick_labels,
                   yticklabels=tick_labels)
        plt.title(f'–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫: {best_model_name}', fontsize=14)
        plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')
        plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')
        
        # 5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ F1
        plt.subplot(2, 3, 5)
        x = np.arange(len(model_names))
        width = 0.35
        
        plt.bar(x - width/2, accuracies, width, label='Accuracy', color='skyblue')
        plt.bar(x + width/2, f1_scores, width, label='F1-Score', color='lightgreen')
        plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ Accuracy –∏ F1-Score', fontsize=14)
        plt.xticks(x, model_names, rotation=45)
        plt.legend()
        
        # 6. –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        plt.subplot(2, 3, 6)
        predict_times = [self.results[name]['predict_time'] for name in model_names]
        
        plt.bar(model_names, predict_times, color='lightblue')
        plt.title('–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è', fontsize=14)
        plt.ylabel('–í—Ä–µ–º—è (—Å–µ–∫)')
        plt.xticks(rotation=45)
        
        plt.suptitle(f'–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ "{self.dataset_name}"', 
                    fontsize=16, y=1.02)
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
        plot_path = self.models_dir / "models_comparison_plot.png"
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.show()
        
        print(f"üìà –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–û–±—É—á–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –æ–±—Ä–∞–∑–æ–≤')
    parser.add_argument('--dataset', type=str, required=True,
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É dataset.npz')
    
    args = parser.parse_args()
    
    print("="*70)
    print("ü§ñ –°–ò–°–¢–ï–ú–ê –û–ë–£–ß–ï–ù–ò–Ø –ò –°–û–•–†–ê–ù–ï–ù–ò–Ø –ú–û–î–ï–õ–ï–ô")
    print("="*70)
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
    trainer = ModelTrainer(args.dataset)
    
    # –û–±—É—á–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
    trainer.train_all_models()
    
    print("\n" + "="*70)
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("="*70)
    print("\nüìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:")
    print("  trained_models/")
    print("  ‚îú‚îÄ‚îÄ model_types/      # –í—Å–µ –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
    print("  ‚îú‚îÄ‚îÄ best_model/       # –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å")
    print("  ‚îú‚îÄ‚îÄ training_report.json   # –û—Ç—á–µ—Ç")
    print("  ‚îî‚îÄ‚îÄ models_comparison.csv  # –¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    print("\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ prediction.py!")


if __name__ == "__main__":
    main()