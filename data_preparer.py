# data_preparer.py - –º–æ–¥—É–ª—å –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from pathlib import Path
import shutil
import json
import pandas as pd
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import random

class DataPreparer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    """
    
    def __init__(self, dataset_name='my_dataset', img_size=(64, 64), grayscale=True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—è –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            dataset_name (str): –ò–º—è –¥–∞—Ç–∞—Å–µ—Ç–∞
            img_size (tuple): –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞)
            grayscale (bool): –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å –≤ –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ
        """
        self.dataset_name = dataset_name
        self.img_size = img_size
        self.grayscale = grayscale
        self.base_dir = Path(dataset_name)
        self.classes = []
        self.class_to_idx = {}
        self.idx_to_class = {}
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        self._create_directories()
    
    def _create_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        directories = ['raw', 'processed', 'train', 'val', 'test', 'metadata']
        
        for dir_name in directories:
            dir_path = self.base_dir / dir_name
            dir_path.mkdir(parents=True, exist_ok=True)
        
        print(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞ –≤: {self.base_dir}")
    
    def organize_data_interactive(self):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        print("\n" + "="*60)
        print("–û–†–ì–ê–ù–ò–ó–ê–¶–ò–Ø –î–ê–ù–ù–´–•")
        print("="*60)
        
        # –ó–∞–ø—Ä–æ—Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–æ–≤
        while True:
            try:
                num_classes = int(input("–í–≤–µ–¥–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: "))
                if num_classes > 0:
                    break
                else:
                    print("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º.")
            except ValueError:
                print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ.")
        
        # –ó–∞–ø—Ä–æ—Å –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤
        self.classes = []
        for i in range(num_classes):
            while True:
                class_name = input(f"–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ {i+1}: ").strip()
                if class_name:
                    self.classes.append(class_name)
                    self.class_to_idx[class_name] = i
                    self.idx_to_class[i] = class_name
                    
                    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫–ª–∞—Å—Å–∞
                    class_dir = self.base_dir / 'raw' / class_name
                    class_dir.mkdir(parents=True, exist_ok=True)
                    
                    print(f"–°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: {class_dir}")
                    print(f"–ü–æ–º–µ—Å—Ç–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JPG, PNG, BMP –≤ —ç—Ç—É –ø–∞–ø–∫—É")
                    input("–ù–∞–∂–º–∏—Ç–µ Enter, –∫–æ–≥–¥–∞ –¥–æ–±–∞–≤–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
                    break
                else:
                    print("–ù–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º.")
        
        print(f"\n–ö–ª–∞—Å—Å—ã —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã: {', '.join(self.classes)}")
        return self.classes
    
    def process_images(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        print("\n" + "="*60)
        print("–û–ë–†–ê–ë–û–¢–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô")
        print("="*60)
        
        raw_dir = self.base_dir / 'raw'
        processed_dir = self.base_dir / 'processed'
        
        image_info = []
        total_images = 0
        
        for class_name in self.classes:
            class_raw_dir = raw_dir / class_name
            class_processed_dir = processed_dir / class_name
            class_processed_dir.mkdir(exist_ok=True)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                image_files.extend(class_raw_dir.glob(ext))
            
            if len(image_files) == 0:
                print(f"‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –∫–ª–∞—Å—Å–µ '{class_name}'")
                continue
            
            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞ '{class_name}' ({len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)...")
            
            for img_file in tqdm(image_files, desc=f"–ö–ª–∞—Å—Å {class_name}"):
                try:
                    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    with Image.open(img_file) as img:
                        original_size = img.size
                        
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                        if self.grayscale:
                            img = img.convert('L')  # –ì—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ
                        else:
                            img = img.convert('RGB')  # –¶–≤–µ—Ç–Ω–æ–µ
                        
                        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
                        img_resized = img.resize(self.img_size, Image.Resampling.LANCZOS)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                        output_path = class_processed_dir / f"{img_file.stem}.png"
                        img_resized.save(output_path, 'PNG')
                        
                        image_info.append({
                            'original_path': str(img_file),
                            'processed_path': str(output_path),
                            'class': class_name,
                            'class_idx': self.class_to_idx[class_name],
                            'original_size': original_size,
                            'processed_size': self.img_size,
                            'grayscale': self.grayscale
                        })
                        
                        total_images += 1
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {img_file}: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
        if image_info:
            df = pd.DataFrame(image_info)
            metadata_dir = self.base_dir / 'metadata'
            df.to_csv(metadata_dir / 'image_info.csv', index=False)
            
            print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
            
            # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
            self._create_visualization(df)
        
        return total_images
    
    def _create_visualization(self, df):
        """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö"""
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º
        plt.figure(figsize=(12, 5))
        
        plt.subplot(1, 2, 1)
        class_counts = df['class'].value_counts()
        bars = plt.bar(class_counts.index, class_counts.values)
        plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –∫–ª–∞—Å—Å–∞–º')
        plt.xlabel('–ö–ª–∞—Å—Å')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        plt.xticks(rotation=45)
        
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height)}', ha='center', va='bottom')
        
        plt.subplot(1, 2, 2)
        if self.grayscale:
            plt.hist(np.random.randn(1000), bins=30, alpha=0.7, color='gray')
        else:
            colors = ['red', 'green', 'blue']
            for i in range(3):
                plt.hist(np.random.randn(1000), bins=30, alpha=0.3, color=colors[i])
        plt.title('–ü—Ä–∏–º–µ—Ä –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã')
        plt.xlabel('–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å')
        plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
        
        plt.tight_layout()
        plt.savefig(self.base_dir / 'metadata' / 'data_distribution.png', dpi=150)
        plt.show()
    
    def split_dataset(self, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏"""
        print("\n" + "="*60)
        print("–†–ê–ó–î–ï–õ–ï–ù–ò–ï –ù–ê –í–´–ë–û–†–ö–ò")
        print("="*60)
        
        processed_dir = self.base_dir / 'processed'
        
        split_info = []
        
        for class_name in self.classes:
            class_dir = processed_dir / class_name
            image_files = list(class_dir.glob('*.png'))
            
            if len(image_files) == 0:
                print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫ –∫–ª–∞—Å—Å–∞ '{class_name}' - –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                continue
            
            # –†–∞–∑–¥–µ–ª—è–µ–º —Ñ–∞–π–ª—ã
            train_files, temp_files = train_test_split(
                image_files, train_size=train_ratio, random_state=42
            )
            
            val_files, test_files = train_test_split(
                temp_files,
                train_size=val_ratio/(val_ratio + test_ratio),
                random_state=42
            )
            
            # –ö–æ–ø–∏—Ä—É–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            for split_type, files in [('train', train_files),
                                     ('val', val_files),
                                     ('test', test_files)]:
                split_class_dir = self.base_dir / split_type / class_name
                split_class_dir.mkdir(parents=True, exist_ok=True)
                
                for file_path in files:
                    shutil.copy2(file_path, split_class_dir / file_path.name)
                    split_info.append({
                        'path': str(split_class_dir / file_path.name),
                        'class': class_name,
                        'split_type': split_type
                    })
            
            print(f"–ö–ª–∞—Å—Å '{class_name}':")
            print(f"  –û–±—É—á–∞—é—â–∞—è: {len(train_files)}")
            print(f"  –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è: {len(val_files)}")
            print(f"  –¢–µ—Å—Ç–æ–≤–∞—è: {len(test_files)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏
        if split_info:
            split_df = pd.DataFrame(split_info)
            metadata_dir = self.base_dir / 'metadata'
            split_df.to_csv(metadata_dir / 'split_info.csv', index=False)
            
            print(f"\n‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            print(f"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–æ: {len(split_info)}")
    
    def create_numpy_dataset(self):
        """–°–æ–∑–¥–∞–µ—Ç numpy –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        print("\n" + "="*60)
        print("–°–û–ó–î–ê–ù–ò–ï –î–ê–¢–ê–°–ï–¢–ê –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø")
        print("="*60)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –≤—ã–±–æ—Ä–æ–∫
        X_train, y_train = self._load_split_data('train')
        X_val, y_val = self._load_split_data('val')
        X_test, y_test = self._load_split_data('test')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å
        if len(X_train) == 0:
            print("‚ùå –û—à–∏–±–∫–∞: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
            return None
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ npz —Ñ–∞–π–ª
        output_file = self.base_dir / 'dataset.npz'
        np.savez_compressed(
            output_file,
            X_train=X_train, y_train=y_train,
            X_val=X_val, y_val=y_val,
            X_test=X_test, y_test=y_test
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'dataset_name': self.dataset_name,
            'classes': self.classes,
            'class_to_idx': self.class_to_idx,
            'image_size': self.img_size,
            'grayscale': self.grayscale,
            'num_train': len(X_train),
            'num_val': len(X_val),
            'num_test': len(X_test),
            'input_shape': X_train[0].shape
        }
        
        metadata_dir = self.base_dir / 'metadata'
        with open(metadata_dir / 'dataset_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"‚úÖ –î–∞—Ç—Å–µ—Ç —Å–æ–∑–¥–∞–Ω!")
        print(f"–§–∞–π–ª: {output_file}")
        print(f"–†–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
        print(f"  –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape}")
        print(f"  –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_val.shape}")
        print(f"  –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape}")
        print(f"  –†–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {X_train[0].shape}")
        
        return output_file
    
    def _load_split_data(self, split_name):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏"""
        split_dir = self.base_dir / split_name
        X = []
        y = []
        
        for class_name in self.classes:
            class_dir = split_dir / class_name
            if class_dir.exists():
                for img_file in class_dir.glob('*.png'):
                    try:
                        with Image.open(img_file) as img:
                            img_array = np.array(img)
                        
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 0 –¥–æ 1
                        img_normalized = img_array.astype(np.float32) / 255.0
                        
                        # –ï—Å–ª–∏ –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ –∏ –º–∞—Å—Å–∏–≤ 2D, –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–∞–Ω–∞–ª–∞
                        if self.grayscale and len(img_normalized.shape) == 2:
                            img_normalized = np.expand_dims(img_normalized, axis=-1)
                        
                        X.append(img_normalized)
                        y.append(self.class_to_idx[class_name])
                        
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {img_file}: {e}")
        
        return np.array(X), np.array(y)
    
    def run_full_pipeline(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
        print("="*70)
        print("–ü–û–õ–ù–´–ô –ö–û–ù–í–ï–ô–ï–† –ü–û–î–ì–û–¢–û–í–ö–ò –î–ê–ù–ù–´–•")
        print("="*70)
        
        # 1. –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        self.organize_data_interactive()
        
        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.process_images()
        
        # 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏
        self.split_dataset()
        
        # 4. –°–æ–∑–¥–∞–Ω–∏–µ numpy –¥–∞—Ç–∞—Å–µ—Ç–∞
        dataset_file = self.create_numpy_dataset()
        
        print("\n" + "="*70)
        print("‚úÖ –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –ó–ê–í–ï–†–®–ï–ù–ê!")
        print("="*70)
        
        return dataset_file


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
def create_dataset():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    print("–ü–†–û–ì–†–ê–ú–ú–ê –ü–û–î–ì–û–¢–û–í–ö–ò –î–ê–ù–ù–´–•")
    print("="*60)
    
    # –ó–∞–ø—Ä–æ—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    print("\n–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    
    dataset_name = input("–ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: my_dataset): ") or "my_dataset"
    
    while True:
        try:
            width = int(input("–®–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 64): ") or "64")
            height = int(input("–í—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 64): ") or "64")
            if width > 0 and height > 0:
                break
            else:
                print("–†–∞–∑–º–µ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏.")
        except ValueError:
            print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞.")
    
    grayscale_input = input("–ì—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ? (y/n, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: y): ").lower()
    grayscale = grayscale_input != 'n'
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å
    preparer = DataPreparer(
        dataset_name=dataset_name,
        img_size=(width, height),
        grayscale=grayscale
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–Ω–≤–µ–π–µ—Ä
    dataset_file = preparer.run_full_pipeline()
    
    if dataset_file:
        print(f"\nüìÅ –í–∞—à –¥–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        print(f"–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É: {dataset_file}")
        print(f"\n–î–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
        print(f"python model_comparison.py --dataset {dataset_file}")
    
    return dataset_file


if __name__ == "__main__":
    create_dataset()