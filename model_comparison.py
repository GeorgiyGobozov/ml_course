# model_comparison_detailed.py - –≤–µ—Ä—Å–∏—è —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –≤—ã–≤–æ–¥–æ–º –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, 
    f1_score, confusion_matrix, classification_report,
    roc_curve, auc
)
from sklearn.model_selection import cross_val_score
import time
import json
import argparse
import sys
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ sklearn
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.preprocessing import label_binarize

class DetailedModelComparator:
    """
    –ö–æ–º–ø–∞—Ä–∞—Ç–æ—Ä –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –≤—ã–≤–æ–¥–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, dataset_path):
        from pathlib import Path
        self.dataset_path = Path(dataset_path)
        self.dataset_name = ""
        self.classes = []
        self.input_shape = None
        self.grayscale = True
        self.results = {}
        self.detailed_reports = {}
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self._load_dataset()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self._prepare_data()
    
    def _load_dataset(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {self.dataset_path}")
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            data = np.load(self.dataset_path)
            
            self.X_train = data['X_train']
            self.y_train = data['y_train']
            self.X_val = data['X_val']
            self.y_val = data['y_val']
            self.X_test = data['X_test']
            self.y_test = data['y_test']
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata_path = self.dataset_path.parent / 'metadata' / 'dataset_metadata.json'
            if metadata_path.exists():
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                self.dataset_name = metadata.get('dataset_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç')
                self.classes = metadata.get('classes', [])
                self.input_shape = metadata.get('input_shape', self.X_train[0].shape)
                self.grayscale = metadata.get('grayscale', True)
                
                print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–¢–ê–°–ï–¢–ï:")
                print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {self.dataset_name}")
                print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(self.classes)}")
                print(f"  –ö–ª–∞—Å—Å—ã: {', '.join(self.classes)}")
                print(f"  –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {self.X_train.shape[0]} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                print(f"  –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {self.X_val.shape[0]} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                print(f"  –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {self.X_test.shape[0]} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                print(f"  –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {self.input_shape}")
                print(f"  –ì—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ: {'–î–∞' if self.grayscale else '–ù–µ—Ç'}")
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
                print(f"\nüìà –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ö–õ–ê–°–°–û–í:")
                for split_name, X_split, y_split in [
                    ('–û–±—É—á–∞—é—â–∞—è', self.X_train, self.y_train),
                    ('–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è', self.X_val, self.y_val),
                    ('–¢–µ—Å—Ç–æ–≤–∞—è', self.X_test, self.y_test)
                ]:
                    unique, counts = np.unique(y_split, return_counts=True)
                    print(f"  {split_name} –≤—ã–±–æ—Ä–∫–∞:")
                    for cls_idx, count in zip(unique, counts):
                        cls_name = self.classes[cls_idx] if cls_idx < len(self.classes) else f'Class_{cls_idx}'
                        percentage = (count / len(y_split)) * 100
                        print(f"    {cls_name}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({percentage:.1f}%)")
                
            else:
                print("‚ö†Ô∏è  –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å—ã
                self.classes = [f'Class_{i}' for i in range(len(np.unique(self.y_train)))]
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
            sys.exit(1)
    
    def _prepare_data(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        print("\nüîß –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è sklearn –º–æ–¥–µ–ª–µ–π
        n_train = self.X_train.shape[0]
        n_val = self.X_val.shape[0]
        n_test = self.X_test.shape[0]
        
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        self.X_train_flat = self.X_train.reshape(n_train, -1)
        self.X_val_flat = self.X_val.reshape(n_val, -1)
        self.X_test_flat = self.X_test.reshape(n_test, -1)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏
        self.X_train_full = np.vstack([self.X_train_flat, self.X_val_flat])
        self.y_train_full = np.concatenate([self.y_train, self.y_val])
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        print(f"  –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {self.X_train_flat.shape}")
        print(f"  –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {self.X_test_flat.shape}")
        print(f"  –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (features): {self.X_train_flat.shape[1]}")
        print(f"  –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π –ø–∏–∫—Å–µ–ª–µ–π: [{self.X_train.min():.3f}, {self.X_train.max():.3f}]")
    
    def _print_model_header(self, model_name):
        """–ü–µ—á–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        print("\n" + "="*70)
        print(f"–ú–û–î–ï–õ–¨: {model_name}")
        print("="*70)
    
    def _print_model_results(self, model_name, results, y_pred):
        """–ü–µ—á–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –î–õ–Ø {model_name}:")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å (Accuracy): {results['accuracy']:.4f}")
        print(f"  F1-–º–µ—Ä–∞: {results['f1_score']:.4f}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å (Precision): {results['precision']:.4f}")
        print(f"  –ü–æ–ª–Ω–æ—Ç–∞ (Recall): {results['recall']:.4f}")
        print(f"  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {results['train_time']:.2f} —Å–µ–∫")
        print(f"  –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {results['predict_time']:.4f} —Å–µ–∫")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º
        if len(self.classes) > 0:
            print(f"\nüìã –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –ö–õ–ê–°–°–ê–ú:")
            report = classification_report(self.y_test, y_pred, 
                                          target_names=self.classes,
                                          output_dict=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            self.detailed_reports[model_name] = report
            
            # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É
            print(f"{'–ö–ª–∞—Å—Å':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}")
            print("-"*55)
            
            for cls in self.classes:
                if cls in report:
                    cls_report = report[cls]
                    print(f"{cls:<15} {cls_report['precision']:<10.3f} "
                          f"{cls_report['recall']:<10.3f} {cls_report['f1-score']:<10.3f} "
                          f"{int(cls_report['support']):<10}")
            
            print("-"*55)
            print(f"{'–°—Ä–µ–¥–Ω–µ–µ/–ò—Ç–æ–≥–æ':<15} {report['weighted avg']['precision']:<10.3f} "
                  f"{report['weighted avg']['recall']:<10.3f} "
                  f"{report['weighted avg']['f1-score']:<10.3f} "
                  f"{int(report['weighted avg']['support']):<10}")
        
        # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self._show_prediction_examples(model_name, y_pred, num_examples=3)
    
    def _show_prediction_examples(self, model_name, y_pred, num_examples=3):
        """–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        print(f"\nüîç –ü–†–ò–ú–ï–†–´ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô:")
        
        # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        correct_indices = np.where(y_pred == self.y_test)[0]
        incorrect_indices = np.where(y_pred != self.y_test)[0]
        
        if len(correct_indices) > 0 and len(incorrect_indices) > 0:
            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
            np.random.seed(42)
            correct_samples = np.random.choice(correct_indices, 
                                              min(num_examples, len(correct_indices)), 
                                              replace=False)
            incorrect_samples = np.random.choice(incorrect_indices, 
                                                min(num_examples, len(incorrect_indices)), 
                                                replace=False)
            
            print("  –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
            for idx in correct_samples:
                true_label = self.classes[self.y_test[idx]] if self.y_test[idx] < len(self.classes) else f'Class_{self.y_test[idx]}'
                pred_label = self.classes[y_pred[idx]] if y_pred[idx] < len(self.classes) else f'Class_{y_pred[idx]}'
                print(f"    –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx}: –ò—Å—Ç–∏–Ω–Ω–æ–µ = {true_label}, –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ = {pred_label}")
            
            print("\n  –û—à–∏–±–æ—á–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
            for idx in incorrect_samples:
                true_label = self.classes[self.y_test[idx]] if self.y_test[idx] < len(self.classes) else f'Class_{self.y_test[idx]}'
                pred_label = self.classes[y_pred[idx]] if y_pred[idx] < len(self.classes) else f'Class_{y_pred[idx]}'
                print(f"    –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx}: –ò—Å—Ç–∏–Ω–Ω–æ–µ = {true_label}, –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ = {pred_label}")
        else:
            print("  –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    
    def evaluate_logistic_regression(self):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"""
        model_name = "Logistic Regression"
        self._print_model_header(model_name)
        
        print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        print("  –ê–ª–≥–æ—Ä–∏—Ç–º: –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è")
        print("  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π: 1000")
        print("  –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è: L2")
        
        model = LogisticRegression(max_iter=1000, random_state=42, verbose=0)
        
        start_time = time.time()
        model.fit(self.X_train_full, self.y_train_full)
        train_time = time.time() - start_time
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        start_time = time.time()
        y_pred_proba = model.predict_proba(self.X_test_flat)
        y_pred = model.predict(self.X_test_flat)
        predict_time = time.time() - start_time
        
        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='weighted', zero_division=0)
        
        results = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'train_time': train_time,
            'predict_time': predict_time,
            'predictions': y_pred,
            'predictions_proba': y_pred_proba
        }
        
        self._print_model_results(model_name, results, y_pred)
        self.results[model_name] = results
        
        return results
    
    def evaluate_svm_linear(self):
        """–û—Ü–µ–Ω–∫–∞ SVM —Å –ª–∏–Ω–µ–π–Ω—ã–º —è–¥—Ä–æ–º"""
        model_name = "SVM (Linear Kernel)"
        self._print_model_header(model_name)
        
        print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        print("  –ê–ª–≥–æ—Ä–∏—Ç–º: –ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤")
        print("  –Ø–¥—Ä–æ: –ª–∏–Ω–µ–π–Ω–æ–µ")
        print("  –ü–∞—Ä–∞–º–µ—Ç—Ä —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ C: 1.0")
        
        model = SVC(kernel='linear', random_state=42, probability=True)
        
        start_time = time.time()
        model.fit(self.X_train_full, self.y_train_full)
        train_time = time.time() - start_time
        
        start_time = time.time()
        y_pred_proba = model.predict_proba(self.X_test_flat)
        y_pred = model.predict(self.X_test_flat)
        predict_time = time.time() - start_time
        
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='weighted', zero_division=0)
        
        results = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'train_time': train_time,
            'predict_time': predict_time,
            'predictions': y_pred,
            'predictions_proba': y_pred_proba
        }
        
        self._print_model_results(model_name, results, y_pred)
        self.results[model_name] = results
        
        return results
    
    def evaluate_svm_rbf(self):
        """–û—Ü–µ–Ω–∫–∞ SVM —Å RBF —è–¥—Ä–æ–º"""
        model_name = "SVM (RBF Kernel)"
        self._print_model_header(model_name)
        
        print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        print("  –ê–ª–≥–æ—Ä–∏—Ç–º: –ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤")
        print("  –Ø–¥—Ä–æ: —Ä–∞–¥–∏–∞–ª—å–Ω–æ-–±–∞–∑–∏—Å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è (RBF)")
        print("  –ü–∞—Ä–∞–º–µ—Ç—Ä —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ C: 1.0")
        print("  –ü–∞—Ä–∞–º–µ—Ç—Ä gamma: 'scale'")
        
        model = SVC(kernel='rbf', random_state=42, probability=True)
        
        start_time = time.time()
        model.fit(self.X_train_full, self.y_train_full)
        train_time = time.time() - start_time
        
        start_time = time.time()
        y_pred_proba = model.predict_proba(self.X_test_flat)
        y_pred = model.predict(self.X_test_flat)
        predict_time = time.time() - start_time
        
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='weighted', zero_division=0)
        
        results = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'train_time': train_time,
            'predict_time': predict_time,
            'predictions': y_pred,
            'predictions_proba': y_pred_proba
        }
        
        self._print_model_results(model_name, results, y_pred)
        self.results[model_name] = results
        
        return results
    
    def evaluate_random_forest(self):
        """–û—Ü–µ–Ω–∫–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞"""
        model_name = "Random Forest"
        self._print_model_header(model_name)
        
        print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        print("  –ê–ª–≥–æ—Ä–∏—Ç–º: –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å")
        print("  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤: 100")
        print("  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞: –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞")
        print("  –ö—Ä–∏—Ç–µ—Ä–∏–π —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è: –∫—Ä–∏—Ç–µ—Ä–∏–π –î–∂–∏–Ω–∏")
        
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        
        start_time = time.time()
        model.fit(self.X_train_full, self.y_train_full)
        train_time = time.time() - start_time
        
        start_time = time.time()
        y_pred_proba = model.predict_proba(self.X_test_flat)
        y_pred = model.predict(self.X_test_flat)
        predict_time = time.time() - start_time
        
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='weighted', zero_division=0)
        
        # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_importance = model.feature_importances_
        top_features = np.argsort(feature_importance)[-5:][::-1]
        
        results = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'train_time': train_time,
            'predict_time': predict_time,
            'predictions': y_pred,
            'predictions_proba': y_pred_proba,
            'feature_importance': feature_importance
        }
        
        self._print_model_results(model_name, results, y_pred)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è Random Forest
        print(f"\nüå≤ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
        print(f"  –°—Ä–µ–¥–Ω—è—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤: {np.mean([tree.tree_.max_depth for tree in model.estimators_]):.1f}")
        print(f"  –¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {top_features[:5]}")
        
        self.results[model_name] = results
        
        return results
    
    def evaluate_knn(self):
        """–û—Ü–µ–Ω–∫–∞ K-–±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π"""
        model_name = "K-Nearest Neighbors"
        self._print_model_header(model_name)
        
        print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        print("  –ê–ª–≥–æ—Ä–∏—Ç–º: K-–±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π")
        print("  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π: 5")
        print("  –ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è: –ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ")
        print("  –í–µ—Å–∞: —Ä–∞–≤–Ω—ã–µ")
        
        model = KNeighborsClassifier(n_neighbors=5)
        
        start_time = time.time()
        model.fit(self.X_train_full, self.y_train_full)
        train_time = time.time() - start_time
        
        start_time = time.time()
        y_pred = model.predict(self.X_test_flat)
        predict_time = time.time() - start_time
        
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='weighted', zero_division=0)
        
        results = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'train_time': train_time,
            'predict_time': predict_time,
            'predictions': y_pred
        }
        
        self._print_model_results(model_name, results, y_pred)
        self.results[model_name] = results
        
        return results
    
    def evaluate_decision_tree(self):
        """–û—Ü–µ–Ω–∫–∞ —Ä–µ—à–∞—é—â–µ–≥–æ –¥–µ—Ä–µ–≤–∞"""
        model_name = "Decision Tree"
        self._print_model_header(model_name)
        
        print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        print("  –ê–ª–≥–æ—Ä–∏—Ç–º: –†–µ—à–∞—é—â–µ–µ –¥–µ—Ä–µ–≤–æ")
        print("  –ö—Ä–∏—Ç–µ—Ä–∏–π —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è: –∫—Ä–∏—Ç–µ—Ä–∏–π –î–∂–∏–Ω–∏")
        print("  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞: –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞")
        print("  –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è: 2")
        
        model = DecisionTreeClassifier(random_state=42)
        
        start_time = time.time()
        model.fit(self.X_train_full, self.y_train_full)
        train_time = time.time() - start_time
        
        start_time = time.time()
        y_pred = model.predict(self.X_test_flat)
        predict_time = time.time() - start_time
        
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='weighted', zero_division=0)
        
        results = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'train_time': train_time,
            'predict_time': predict_time,
            'predictions': y_pred
        }
        
        self._print_model_results(model_name, results, y_pred)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è Decision Tree
        print(f"\nüå≥ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
        print(f"  –ì–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞: {model.get_depth()}")
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Å—Ç—å–µ–≤: {model.get_n_leaves()}")
        
        self.results[model_name] = results
        
        return results
    
    def evaluate_naive_bayes(self):
        """–û—Ü–µ–Ω–∫–∞ –Ω–∞–∏–≤–Ω–æ–≥–æ –ë–∞–π–µ—Å–∞"""
        model_name = "Gaussian Naive Bayes"
        self._print_model_header(model_name)
        
        print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        print("  –ê–ª–≥–æ—Ä–∏—Ç–º: –ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å (–ì–∞—É—Å—Å–æ–≤—Å–∫–∏–π)")
        print("  –ü—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ: –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã –∏ –∏–º–µ—é—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ")
        
        model = GaussianNB()
        
        start_time = time.time()
        model.fit(self.X_train_full, self.y_train_full)
        train_time = time.time() - start_time
        
        start_time = time.time()
        y_pred_proba = model.predict_proba(self.X_test_flat)
        y_pred = model.predict(self.X_test_flat)
        predict_time = time.time() - start_time
        
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='weighted', zero_division=0)
        
        results = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'train_time': train_time,
            'predict_time': predict_time,
            'predictions': y_pred,
            'predictions_proba': y_pred_proba
        }
        
        self._print_model_results(model_name, results, y_pred)
        self.results[model_name] = results
        
        return results
    
    def evaluate_mlp(self):
        """–û—Ü–µ–Ω–∫–∞ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–æ–≥–æ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞"""
        model_name = "Neural Network (MLP)"
        self._print_model_header(model_name)
        
        print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        print("  –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–π –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω")
        print("  –°–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏: (128, 64) –Ω–µ–π—Ä–æ–Ω–æ–≤")
        print("  –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: ReLU")
        print("  –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: Adam")
        print("  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö: 500")
        
        model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, 
                             random_state=42, verbose=False)
        
        start_time = time.time()
        model.fit(self.X_train_full, self.y_train_full)
        train_time = time.time() - start_time
        
        start_time = time.time()
        y_pred_proba = model.predict_proba(self.X_test_flat)
        y_pred = model.predict(self.X_test_flat)
        predict_time = time.time() - start_time
        
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='weighted', zero_division=0)
        
        results = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'train_time': train_time,
            'predict_time': predict_time,
            'predictions': y_pred,
            'predictions_proba': y_pred_proba,
            'n_iter': model.n_iter_,
            'loss_curve': model.loss_curve_
        }
        
        self._print_model_results(model_name, results, y_pred)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è MLP
        print(f"\nüß† –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –æ–±—É—á–µ–Ω–∏—è: {model.n_iter_}")
        print(f"  –§–∏–Ω–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å: {model.loss_:.4f}")
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤: {len(model.hidden_layer_sizes)}")
        
        self.results[model_name] = results
        
        return results
    
    def run_all_models(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –≤—ã–≤–æ–¥–æ–º"""
        print("\n" + "="*80)
        print("üöÄ –ó–ê–ü–£–°–ö –ü–û–î–†–û–ë–ù–û–ì–û –°–†–ê–í–ù–ï–ù–ò–Ø –ú–û–î–ï–õ–ï–ô")
        print("="*80)
        
        # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        models_to_evaluate = [
            ("Logistic Regression", self.evaluate_logistic_regression),
            ("SVM (Linear Kernel)", self.evaluate_svm_linear),
            ("SVM (RBF Kernel)", self.evaluate_svm_rbf),
            ("Random Forest", self.evaluate_random_forest),
            ("K-Nearest Neighbors", self.evaluate_knn),
            ("Decision Tree", self.evaluate_decision_tree),
            ("Gaussian Naive Bayes", self.evaluate_naive_bayes),
            ("Neural Network (MLP)", self.evaluate_mlp)
        ]
        
        for model_name, evaluate_func in models_to_evaluate:
            try:
                print(f"\n‚ñ∂Ô∏è  –ù–ê–ß–ò–ù–ê–Æ –û–¶–ï–ù–ö–£: {model_name}")
                evaluate_func()
                print(f"‚úÖ {model_name} - –û–¶–ï–ù–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ {model_name}: {e}")
                import traceback
                traceback.print_exc()
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.compare_all_results()
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        self.visualize_comparison()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.save_detailed_results()
    
    def compare_all_results(self):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        print("\n" + "="*80)
        print("üìà –°–í–û–î–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –í–°–ï–• –ú–û–î–ï–õ–ï–ô")
        print("="*80)
        
        if not self.results:
            print("‚ö†Ô∏è  –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            return
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        comparison_data = []
        
        for model_name, res in self.results.items():
            comparison_data.append({
                'Model': model_name,
                'Accuracy': f"{res['accuracy']:.4f}",
                'F1-Score': f"{res['f1_score']:.4f}",
                'Precision': f"{res['precision']:.4f}",
                'Recall': f"{res['recall']:.4f}",
                'Train Time (s)': f"{res['train_time']:.2f}",
                'Predict Time (s)': f"{res['predict_time']:.4f}"
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
        comparison_data.sort(key=lambda x: float(x['Accuracy']), reverse=True)
        
        # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É
        print("\n" + "-"*110)
        print(f"{'–ú–û–î–ï–õ–¨':<25} {'–¢–û–ß–ù–û–°–¢–¨':<12} {'F1-–ú–ï–†–ê':<12} {'–¢–û–ß–ù–û–°–¢–¨ (prec)':<15} {'–ü–û–õ–ù–û–¢–ê':<12} {'–û–ë–£–ß–ï–ù–ò–ï (—Å)':<12} {'–ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï (—Å)':<15}")
        print("-"*110)
        
        for i, row in enumerate(comparison_data):
            if i == 0:
                # –í—ã–¥–µ–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                print(f"üèÜ {row['Model']:<23} {row['Accuracy']:<12} {row['F1-Score']:<12} "
                      f"{row['Precision']:<15} {row['Recall']:<12} "
                      f"{row['Train Time (s)']:<12} {row['Predict Time (s)']:<15}")
            else:
                print(f"   {row['Model']:<25} {row['Accuracy']:<12} {row['F1-Score']:<12} "
                      f"{row['Precision']:<15} {row['Recall']:<12} "
                      f"{row['Train Time (s)']:<12} {row['Predict Time (s)']:<15}")
        
        print("-"*110)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        best_model = comparison_data[0]['Model']
        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model}")
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {len(comparison_data)}")
        print(f"  –î–∏–∞–ø–∞–∑–æ–Ω —Ç–æ—á–Ω–æ—Å—Ç–∏: {float(comparison_data[-1]['Accuracy']):.4f} - {float(comparison_data[0]['Accuracy']):.4f}")
        print(f"  –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å: {np.mean([float(row['Accuracy']) for row in comparison_data]):.4f}")
    
    def visualize_comparison(self):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
        if not self.results:
            return
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
        fig = plt.figure(figsize=(20, 12))
        fig.suptitle(f'–î–ï–¢–ê–õ–¨–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ù–ê –î–ê–¢–ê–°–ï–¢–ï "{self.dataset_name}"', 
                    fontsize=16, y=1.02)
        
        # 1. –û—Å–Ω–æ–≤–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
        ax1 = plt.subplot(2, 3, 1)
        model_names = list(self.results.keys())
        accuracies = [self.results[name]['accuracy'] for name in model_names]
        
        bars = ax1.bar(model_names, accuracies, color=plt.cm.Set3(np.arange(len(model_names))/len(model_names)))
        ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π', fontsize=14)
        ax1.set_ylabel('Accuracy')
        ax1.set_ylim(0, 1.1)
        ax1.tick_params(axis='x', rotation=45)
        ax1.grid(True, alpha=0.3, axis='y')
        
        for bar, acc in zip(bars, accuracies):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{acc:.3f}', ha='center', va='bottom', fontsize=10)
        
        # 2. –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
        ax2 = plt.subplot(2, 3, 2)
        train_times = [self.results[name]['train_time'] for name in model_names]
        
        bars = ax2.bar(model_names, train_times, color='lightcoral')
        ax2.set_title('–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π', fontsize=14)
        ax2.set_ylabel('–í—Ä–µ–º—è (—Å–µ–∫—É–Ω–¥—ã)')
        ax2.tick_params(axis='x', rotation=45)
        ax2.grid(True, alpha=0.3, axis='y')
        
        for bar, time_val in zip(bars, train_times):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{time_val:.1f}', ha='center', va='bottom', fontsize=9)
        
        # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        ax3 = plt.subplot(2, 3, 3)
        f1_scores = [self.results[name]['f1_score'] for name in model_names]
        precisions = [self.results[name]['precision'] for name in model_names]
        recalls = [self.results[name]['recall'] for name in model_names]
        
        x = np.arange(len(model_names))
        width = 0.25
        
        ax3.bar(x - width, accuracies, width, label='Accuracy', color='skyblue')
        ax3.bar(x, f1_scores, width, label='F1-Score', color='lightgreen')
        ax3.bar(x + width, precisions, width, label='Precision', color='salmon')
        
        ax3.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞', fontsize=14)
        ax3.set_xticks(x)
        ax3.set_xticklabels(model_names, rotation=45)
        ax3.legend()
        ax3.grid(True, alpha=0.3, axis='y')
        
        # 4. –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        ax4 = plt.subplot(2, 3, 4)
        best_model_name = max(self.results.keys(), key=lambda x: self.results[x]['accuracy'])
        best_predictions = self.results[best_model_name]['predictions']
        
        cm = confusion_matrix(self.y_test, best_predictions)
        
        if self.classes and len(self.classes) == cm.shape[0]:
            tick_labels = self.classes
        else:
            tick_labels = [f'Class {i}' for i in range(cm.shape[0])]
        
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=tick_labels,
                   yticklabels=tick_labels,
                   ax=ax4)
        ax4.set_title(f'–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫: {best_model_name}', fontsize=14)
        ax4.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')
        ax4.set_ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')
        
        # 5. ROC-–∫—Ä–∏–≤—ã–µ –¥–ª—è –º–æ–¥–µ–ª–µ–π —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
        ax5 = plt.subplot(2, 3, 5)
        
        if len(np.unique(self.y_test)) == 2:  # –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
            ax5.set_title('ROC-–∫—Ä–∏–≤—ã–µ –º–æ–¥–µ–ª–µ–π', fontsize=14)
            ax5.set_xlabel('False Positive Rate')
            ax5.set_ylabel('True Positive Rate')
            ax5.plot([0, 1], [0, 1], 'k--', label='–°–ª—É—á–∞–π–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä')
            
            for model_name, res in self.results.items():
                if 'predictions_proba' in res:
                    fpr, tpr, _ = roc_curve(self.y_test, res['predictions_proba'][:, 1])
                    roc_auc = auc(fpr, tpr)
                    ax5.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.3f})')
            
            ax5.legend(loc='lower right')
            ax5.grid(True, alpha=0.3)
        else:
            # –î–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
            ax5.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è', fontsize=14)
            
            predict_times = [self.results[name]['predict_time'] for name in model_names]
            
            x = np.arange(len(model_names))
            ax5.bar(x - 0.2, train_times, 0.4, label='–û–±—É—á–µ–Ω–∏–µ', color='lightcoral')
            ax5.bar(x + 0.2, predict_times, 0.4, label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ', color='lightblue')
            
            ax5.set_xticks(x)
            ax5.set_xticklabels(model_names, rotation=45)
            ax5.set_ylabel('–í—Ä–µ–º—è (—Å–µ–∫—É–Ω–¥—ã)')
            ax5.legend()
            ax5.grid(True, alpha=0.3)
        
        # 6. –ö—Ä–∏–≤–∞—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è MLP (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
        ax6 = plt.subplot(2, 3, 6)
        
        if 'Neural Network (MLP)' in self.results and 'loss_curve' in self.results['Neural Network (MLP)']:
            loss_curve = self.results['Neural Network (MLP)']['loss_curve']
            ax6.plot(loss_curve, label='–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å')
            ax6.set_title('–ö—Ä–∏–≤–∞—è –æ–±—É—á–µ–Ω–∏—è MLP', fontsize=14)
            ax6.set_xlabel('–ò—Ç–µ—Ä–∞—Ü–∏—è')
            ax6.set_ylabel('Loss')
            ax6.legend()
            ax6.grid(True, alpha=0.3)
        else:
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            ax6.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π', fontsize=14)
            ax6.hist(accuracies, bins=10, edgecolor='black', alpha=0.7)
            ax6.set_xlabel('–¢–æ—á–Ω–æ—Å—Ç—å')
            ax6.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π')
            ax6.axvline(np.mean(accuracies), color='red', linestyle='--', 
                       label=f'–°—Ä–µ–¥–Ω–µ–µ: {np.mean(accuracies):.3f}')
            ax6.legend()
            ax6.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'{self.dataset_name}_detailed_comparison.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        self._create_additional_visualizations()
    
    def _create_additional_visualizations(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π"""
        # –ì—Ä–∞—Ñ–∏–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: –í—Ä–µ–º—è vs –¢–æ—á–Ω–æ—Å—Ç—å
        model_names = list(self.results.keys())
        accuracies = [self.results[name]['accuracy'] for name in model_names]
        train_times = [self.results[name]['train_time'] for name in model_names]
        
        scatter = axes[0].scatter(train_times, accuracies, s=100, alpha=0.7)
        axes[0].set_xlabel('–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (—Å–µ–∫)')
        axes[0].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
        axes[0].set_title('–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –í—Ä–µ–º—è vs –¢–æ—á–Ω–æ—Å—Ç—å')
        axes[0].grid(True, alpha=0.3)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏
        for i, name in enumerate(model_names):
            axes[0].annotate(name, (train_times[i], accuracies[i]), 
                           fontsize=8, alpha=0.8)
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: F1-Score –ø–æ –∫–ª–∞—Å—Å–∞–º –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        best_model_name = max(self.results.keys(), key=lambda x: self.results[x]['accuracy'])
        
        if best_model_name in self.detailed_reports:
            report = self.detailed_reports[best_model_name]
            classes = self.classes if self.classes else [f'Class {i}' for i in range(len(report)-3)]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º F1-Score –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
            f1_scores = []
            valid_classes = []
            
            for cls in classes:
                if cls in report:
                    f1_scores.append(report[cls]['f1-score'])
                    valid_classes.append(cls)
            
            if f1_scores:
                axes[1].bar(valid_classes, f1_scores, color='lightgreen')
                axes[1].set_xlabel('–ö–ª–∞—Å—Å')
                axes[1].set_ylabel('F1-Score')
                axes[1].set_title(f'F1-Score –ø–æ –∫–ª–∞—Å—Å–∞–º ({best_model_name})')
                axes[1].tick_params(axis='x', rotation=45)
                axes[1].set_ylim(0, 1.1)
                axes[1].grid(True, alpha=0.3, axis='y')
                
                for i, (cls, score) in enumerate(zip(valid_classes, f1_scores)):
                    axes[1].text(i, score + 0.02, f'{score:.2f}', 
                               ha='center', fontsize=9)
        
        plt.tight_layout()
        plt.savefig(f'{self.dataset_name}_performance_analysis.png', dpi=150)
        plt.show()
    
    def save_detailed_results(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not self.results:
            return
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        output_data = {
            'dataset_info': {
                'name': self.dataset_name,
                'classes': self.classes,
                'image_size': self.input_shape,
                'grayscale': self.grayscale,
                'train_samples': self.X_train.shape[0],
                'test_samples': self.X_test.shape[0]
            },
            'models_results': {},
            'summary': {
                'best_model': None,
                'best_accuracy': 0
            }
        }
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–µ–π
        for name, res in self.results.items():
            output_data['models_results'][name] = {
                'accuracy': float(res['accuracy']),
                'f1_score': float(res['f1_score']),
                'precision': float(res['precision']),
                'recall': float(res['recall']),
                'train_time': float(res['train_time']),
                'predict_time': float(res['predict_time'])
            }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            if res['accuracy'] > output_data['summary']['best_accuracy']:
                output_data['summary']['best_model'] = name
                output_data['summary']['best_accuracy'] = float(res['accuracy'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
        if self.detailed_reports:
            output_data['detailed_reports'] = self.detailed_reports
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        output_file = f'{self.dataset_name}_detailed_results.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ –ü–û–î–†–û–ë–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–•–†–ê–ù–ï–ù–´:")
        print(f"  –§–∞–π–ª: {output_file}")
        print(f"  –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {output_data['summary']['best_model']}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {output_data['summary']['best_accuracy']:.4f}")
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        import pandas as pd
        csv_data = []
        for name, res in output_data['models_results'].items():
            csv_data.append({
                'Model': name,
                'Accuracy': res['accuracy'],
                'F1_Score': res['f1_score'],
                'Precision': res['precision'],
                'Recall': res['recall'],
                'Train_Time_s': res['train_time'],
                'Predict_Time_s': res['predict_time']
            })
        
        df = pd.DataFrame(csv_data)
        df.to_csv(f'{self.dataset_name}_results_table.csv', index=False)
        print(f"  –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {self.dataset_name}_results_table.csv")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ü–æ–¥—Ä–æ–±–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –æ–±—Ä–∞–∑–æ–≤')
    parser.add_argument('--dataset', type=str, required=True,
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É dataset.npz')
    
    args = parser.parse_args()
    
    print("="*80)
    print("ü§ñ –°–ò–°–¢–ï–ú–ê –ü–û–î–†–û–ë–ù–û–ì–û –°–†–ê–í–ù–ï–ù–ò–Ø –ú–û–î–ï–õ–ï–ô –ú–ê–®–ò–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
    print("="*80)
    print("–í–µ—Ä—Å–∏—è —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –≤—ã–≤–æ–¥–æ–º –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏")
    print("="*80)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞—Ä–∞—Ç–æ—Ä
    comparator = DetailedModelComparator(args.dataset)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    comparator.run_all_models()
    
    print("\n" + "="*80)
    print("üéâ –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û!")
    print("="*80)
    print("\nüìã –ò–¢–û–ì–ò:")
    print("  1. –ö–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å –±—ã–ª–∞ –ø–æ–¥—Ä–æ–±–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    print("  2. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª—ã JSON –∏ CSV")
    print("  3. –°–æ–∑–¥–∞–Ω—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    print("  4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞")
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")


if __name__ == "__main__":
    main()